{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model creation, training, and text generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#!pip install language_tool_python\n",
    "#!pip install textstat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:12.985757400Z",
     "start_time": "2023-08-31T12:06:12.901244600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:15.994631300Z",
     "start_time": "2023-08-31T12:06:12.916299900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import language_tool_python\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#get the data\n",
    "df = pd.read_csv('Final Data.csv', engine = 'python')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:16.211753Z",
     "start_time": "2023-08-31T12:06:15.996962200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "468\n",
      "470\n",
      "519\n",
      "526\n",
      "529\n",
      "539\n",
      "545\n",
      "549\n",
      "552\n",
      "554\n",
      "564\n",
      "565\n",
      "569\n",
      "575\n",
      "578\n",
      "579\n"
     ]
    }
   ],
   "source": [
    "#need to find max text length for padding\n",
    "full_text = ''\n",
    "max_text_length = 0\n",
    "for i in range(0, len(df)):\n",
    "    desc = df['Quest Description'].iloc[i]\n",
    "    try:\n",
    "        assert(type(desc) == str)\n",
    "    except:\n",
    "        continue\n",
    "    title = df['Quest Title'].iloc[i]\n",
    "    new_text = 'Title: '+title+'\\nDescription: '+desc\n",
    "    full_text = full_text+new_text\n",
    "    if len(new_text) > max_text_length:\n",
    "        print(len(new_text))\n",
    "        max_text_length = len(new_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.160119500Z",
     "start_time": "2023-08-31T12:06:16.214753300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "579"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_text_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.175492800Z",
     "start_time": "2023-08-31T12:06:18.162120100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "vocab = sorted(set(full_text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.267639900Z",
     "start_time": "2023-08-31T12:06:18.175492800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '\\r', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '~'] 91\n"
     ]
    }
   ],
   "source": [
    "print(vocab, len(vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.282926800Z",
     "start_time": "2023-08-31T12:06:18.269640900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Defining the encoding / decoding structure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#layer for turning individual characters to IDs\n",
    "chars_to_id_layer = tf.keras.layers.StringLookup(\n",
    "    vocabulary=vocab, mask_token=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.407156200Z",
     "start_time": "2023-08-31T12:06:18.283926800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#inverted version, IDs to characters\n",
    "id_to_chars_layer = tf.keras.layers.StringLookup(\n",
    "    vocabulary=chars_to_id_layer.get_vocabulary(), invert=True, mask_token=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.423974200Z",
     "start_time": "2023-08-31T12:06:18.408156800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#function for encoding\n",
    "def text_to_id(input_val):\n",
    "    return chars_to_id_layer(tf.strings.unicode_split(input_val, input_encoding='UTF-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.443225Z",
     "start_time": "2023-08-31T12:06:18.422974400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#function for decoding\n",
    "def id_to_text(input_val):\n",
    "    return tf.strings.reduce_join(id_to_chars_layer(input_val), axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:18.453744500Z",
     "start_time": "2023-08-31T12:06:18.438222600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#One big string to sample from\n",
    "padded_text = ''\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        assert(type(df['Quest Description'].loc[i]) == str)\n",
    "        pads = (max_text_length+5) - len('Title: '+df['Quest Title'].iloc[i]+'\\nDescription: '+df['Quest Description'].loc[i])\n",
    "    except:\n",
    "        continue\n",
    "    new_text = 'Title: '+df['Quest Title'].iloc[i]+'\\nDescription: '+df['Quest Description'].loc[i]+' '*pads\n",
    "    padded_text = padded_text+new_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:24.612636300Z",
     "start_time": "2023-08-31T12:06:18.453744500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#Model makes predictions character by character, shift each sample by one to train the model\n",
    "def split_input_target(seq):\n",
    "    input_val = seq[:-1]\n",
    "    output_val = seq[1:]\n",
    "    return input_val, output_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:24.627728Z",
     "start_time": "2023-08-31T12:06:24.613636300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#one quest = one sample\n",
    "seq_len = max_text_length-1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:24.649714800Z",
     "start_time": "2023-08-31T12:06:24.630728900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "per_epoch = len(padded_text) // seq_len+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:24.658346500Z",
     "start_time": "2023-08-31T12:06:24.644676700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "ids = text_to_id(padded_text)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.618322900Z",
     "start_time": "2023-08-31T12:06:24.660346400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "sequences = dataset.batch(seq_len + 1, drop_remainder=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.632347400Z",
     "start_time": "2023-08-31T12:06:27.619323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Title: Sharptalon's Claw\\nDescription: The mighty hippogryph Sharptalon has been slain, with the claw of the felled beast serving as a testament to your victory.\\n\\nSenani Thunderheart at the Silverwind Refuge will no doubt be interested in seeing this trophy as proof of your deeds.                                                                                                                                                                                                                                                                                                           \", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "#example of a quest as it is fed into the model. Note the padding\n",
    "for seq in sequences.take(1):\n",
    "    print(id_to_text(seq))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.709090200Z",
     "start_time": "2023-08-31T12:06:27.634347400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.771779100Z",
     "start_time": "2023-08-31T12:06:27.710592200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<_MapDataset element_spec=(TensorSpec(shape=(578,), dtype=tf.int64, name=None), TensorSpec(shape=(578,), dtype=tf.int64, name=None))>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.773779500Z",
     "start_time": "2023-08-31T12:06:27.757765200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 578), dtype=tf.int64, name=None), TensorSpec(shape=(64, 578), dtype=tf.int64, name=None))>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.789643600Z",
     "start_time": "2023-08-31T12:06:27.774779600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.833668500Z",
     "start_time": "2023-08-31T12:06:27.790643500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#simple model structure, we only add three layers\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        #embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        #GRU layer\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            rnn_units, return_sequences=True, return_state=True\n",
    "        )\n",
    "        #Dense layer\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        #Use precious state in training, initialise the model if there is no precious state\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.839646Z",
     "start_time": "2023-08-31T12:06:27.807422Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=len(chars_to_id_layer.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:27.850706400Z",
     "start_time": "2023-08-31T12:06:27.833668500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 578, 92) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\n",
    "        example_batch_predictions.shape,\n",
    "        \"# (batch_size, sequence_length, vocab_size)\",\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.375525700Z",
     "start_time": "2023-08-31T12:06:27.852707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  23552     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  94300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4056156 (15.47 MB)\n",
      "Trainable params: 4056156 (15.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.391144Z",
     "start_time": "2023-08-31T12:06:34.377030900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.435804700Z",
     "start_time": "2023-08-31T12:06:34.393144800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.441909500Z",
     "start_time": "2023-08-31T12:06:34.406761800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix, save_weights_only=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.441909500Z",
     "start_time": "2023-08-31T12:06:34.435804700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Training the model. Once this is done, we can save the weights to load the model quickly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_weights('desctitle_weights.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#model.load_weights('desctitle_weights.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.487365900Z",
     "start_time": "2023-08-31T12:06:34.438908400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, id_to_chars_layer, chars_to_id_layer, temperature=0.3):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = id_to_chars_layer\n",
    "        self.ids_from_chars = chars_to_id_layer\n",
    "\n",
    "        #Prevent [UNK] generation\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(chars_to_id_layer.get_vocabulary())],\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to IDs\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(\n",
    "            inputs=input_ids, states=states, return_state=True\n",
    "        )\n",
    "        # Only use the last prediction\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state\n",
    "        return predicted_chars, states"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.499006600Z",
     "start_time": "2023-08-31T12:06:34.486365600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, id_to_chars_layer, chars_to_id_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.521152400Z",
     "start_time": "2023-08-31T12:06:34.500007200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "text_eval = language_tool_python.LanguageToolPublicAPI('en-US')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.730647700Z",
     "start_time": "2023-08-31T12:06:34.515776700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#function for generating quests\n",
    "def generate_quests(rep = 5, prompt = 'Title: '):\n",
    "    #By default get no prompt and generate 5 responses.\n",
    "    require_input = True\n",
    "    while require_input:\n",
    "        decision = input('Use default settings? Y/N\\nDefault Settings:\\nOutputs: 5\\nPrompt: None')\n",
    "        if decision.lower() in ['y', 'n']:\n",
    "            require_input = False\n",
    "    if decision.lower() == 'n': #option for custom settings\n",
    "        require_input = True\n",
    "        while require_input:\n",
    "            decision = input('Please give the desired number of outputs (default=5)')\n",
    "            try:\n",
    "                decision = int(decision)\n",
    "                assert(decision > 0)\n",
    "            except:\n",
    "                continue\n",
    "            require_input = False\n",
    "            rep = decision\n",
    "        require_input = True\n",
    "        while require_input:\n",
    "            title_decision = input('Please give the desired Title: (default=None, required)')\n",
    "            if not decision:\n",
    "                continue    #a title must be provided\n",
    "            description_decision = input('Please give the desired Description: (default = None, optional)')\n",
    "            if not description_decision:\n",
    "                description_decision = ''   #a description prompt is optional\n",
    "            require_input = False\n",
    "            prompt = 'Title: '+title_decision+'\\nDescription: '+description_decision\n",
    "    total_mistakes = 0      #keep track of grammar mistakes\n",
    "    total_reading_score = 0 #keep track of reading ease score\n",
    "    for i in range (rep):\n",
    "        i =  0\n",
    "        start = time.time() #get time taken to generate each response\n",
    "        states = None\n",
    "        next_char = tf.constant([prompt])\n",
    "        result = [next_char]\n",
    "        for n in range(max_text_length):\n",
    "            next_char, states = one_step_model.generate_one_step(\n",
    "                next_char, states=states\n",
    "            )\n",
    "            result.append(next_char)\n",
    "        result = tf.strings.join(result)\n",
    "        end = time.time()\n",
    "        print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
    "        total_reading_score = total_reading_score + textstat.flesch_reading_ease(result[0].numpy().decode(\"utf-8\"))\n",
    "        total_mistakes = total_mistakes + len(text_eval.check(result[0].numpy().decode(\"utf-8\")))\n",
    "        print(\"\\nRun time:\", end - start)\n",
    "        i+=1\n",
    "    print(f'Average grammar mistakes: {total_mistakes/rep}')\n",
    "    print(f'Average reading score: {total_reading_score/rep}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:06:34.772247900Z",
     "start_time": "2023-08-31T12:06:34.750789400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#function for sampling random original quest\n",
    "def quest_examples():\n",
    "    bad_input = True\n",
    "    while bad_input:    #Get user input for number of responses\n",
    "        ex_count = input('How many examples would you like?')\n",
    "        try:\n",
    "            ex_count = int(ex_count)\n",
    "            assert(ex_count > 0)\n",
    "        except:\n",
    "            continue\n",
    "        bad_input = False\n",
    "    examples = []\n",
    "    index_list = []\n",
    "    for i in range(0, ex_count):\n",
    "        bad_response = True\n",
    "        while bad_response:\n",
    "            index = random.randint(0, len(df))\n",
    "            try:\n",
    "                assert index not in index_list\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                assert type(df['Quest Description'].iloc[index]) == str\n",
    "            except:\n",
    "                continue\n",
    "            bad_response = False\n",
    "            examples.append('Title: '+df['Quest Title'].iloc[index]+'\\nDescription: '+df['Quest Description'].iloc[index]+'\\n\\n' + '_' * 80)\n",
    "            index_list.append(index)\n",
    "    total_mistakes = 0  #get the grammar mistakes and reading score to compare with generated quests\n",
    "    total_reading_score = 0\n",
    "    for x in examples:\n",
    "        print(x)\n",
    "        total_reading_score = total_reading_score + textstat.flesch_reading_ease(x)\n",
    "        total_mistakes = total_mistakes + len(text_eval.check(x))\n",
    "    print(f'Average grammar mistakes: {total_mistakes/ex_count}')\n",
    "    print(f'Average reading score: {total_reading_score/ex_count}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:07:33.694640300Z",
     "start_time": "2023-08-31T12:07:33.674369200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The First Ones Fell Kells\n",
      "Description: The demons seem to be made of a new protoform construct. Present it to an appropriate protoform forge and it may instantiate one of these creatures for you.>                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.6239538192749023\n",
      "Title: The Final Forces\n",
      "Description: I am afraid there were some sort of stronger ships that we were able to help the Horde in the way. We have to stop them before they become the magic of their village.\r\n",
      "\r\n",
      "The power of the arcane magic is strong enough to take us to the south. They will need to be ready to keep them out of the survivors.\r\n",
      "\r\n",
      "There is a lone garden along the road to the north of the Horde on the eastern portals of the Forgotten Phaetic. They should be able to use them to create a sufficient assault on the eastern borders of Shadowmoon Village.                      \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.45952415466308594\n",
      "Title: The First Ones Find: Nazmir\n",
      "Description: The final of my concoction is not the only one. \r\n",
      "\r\n",
      "The other recent customers have seen before us to the north. I would like to see if they are not any concerns about it.\r\n",
      "\r\n",
      "I can sense the power that may have been able to track down my post.                                                                                                                                                                                                                                                                                                        \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.4413478374481201\n",
      "Title: The Wardens Carried Back and Gathering\n",
      "Description: I have received a request from all of the gardens to the southeast. It was once a search for me, though. I have been trying to tell me what we can to save him.\n",
      "\n",
      "I want you to go in there and execute the rest of them.\n",
      "\n",
      "I will send my once to the Light.                                                                                                                                                                                                                                                                                     \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.4435555934906006\n",
      "Title: The Trial of Storms\n",
      "Description: The ship is powerful, {name}. And there is a serious life experienced with enemies.\n",
      "\n",
      "The Shadow Council has seen the enemy of the Shadowlands as a well-worthy of ascending to the Lich King's minions. The shape of the camp is a stable of stone, but one of the most powerful sorceresses at the tomb is a massive creature of the Shadowlands. They are the largest of the tunnels in the area.\n",
      "\n",
      "Travel to the area southwest of the Valley of Fallen Heroes and north of Corp'rethar. There, the Scourge raises dead heroes and turns them against us. Defeat \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.5036087036132812\n",
      "Average grammar mistakes: 3.6\n",
      "Average reading score: 81.226\n"
     ]
    }
   ],
   "source": [
    "generate_quests()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:07:44.735621300Z",
     "start_time": "2023-08-31T12:07:34.643623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Path of Anguish\n",
      "Description: Doom Lord Kazzak commands the Burning Legion in Outland. While we can't get to Kazzak - yet - we can and must get to his lieutenants that command Legion troops from the ground.\n",
      "\n",
      "They have stationed dreadlords at the Path of Anguish, east of here. They are the ones responsible for these infernal storms that rain down upon our heads. To take them and their minions out would be a great set back to the Burning Legion.\n",
      "\n",
      "________________________________________________________________________________\n",
      "Average grammar mistakes: 3.0\n",
      "Average reading score: 80.21\n"
     ]
    }
   ],
   "source": [
    "quest_examples()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T12:07:47.072171500Z",
     "start_time": "2023-08-31T12:07:44.735621300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
